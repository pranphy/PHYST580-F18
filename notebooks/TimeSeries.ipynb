{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "G. Richards (2016, 2018), with materials from Connolly and Ivezic;  Chapter 10 in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pre-Lecture Items\n",
    "\n",
    "- make sure that `pymc` is installed:  \n",
    "```\n",
    "conda install pymc\n",
    "```\n",
    "- install these two packages:\n",
    "```\n",
    "pip install gatspy\n",
    "pip install supersmoother\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From [http://www.astroml.org/gatspy/](http://www.astroml.org/gatspy/):\n",
    "\n",
    "![Gatspy web page](figures/gatspy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "GTR: This gets taken care of later by resetting a parameter in astroML.\n",
    "\n",
    "- replace the first line below with the second line in\n",
    "/astroML/astroML/datasets/rrlyrae_templates.py,\n",
    "where you can determine the path from the error below.\n",
    "\n",
    "#DATA_URL = (\"http://www.astro.washington.edu/users/bsesar/S82_RRLyr/RRLyr_ugriz_templates.tar.gz\")                     \n",
    "DATA_URL = (\"http://www2.mpia-hd.mpg.de/~bsesar/S82_RRLyr/RRLyr_ugriz_templates.tar.gz\")\n",
    "\n",
    "If this doesn't work, then delete the error message that got saved instead of the file in\n",
    "\n",
    "~/astroML_data\n",
    "\n",
    "then try again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Time series analysis is, in many ways, very similar to regression analysis from Chapter 8, except that we replace $x$ with $t$.  However, we have generally assumed that the $y$ values are independent, whereas for time series $y_{i+1}$ is likely to depend directly on $y_i$.  Furthermore, we make no assumptions about the regularity of the time sampling.\n",
    "\n",
    "There is a broad range of variability signatures that we want to be aware of. From transient events to periodic variables to stochastic sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eyer and Mowlavi (2007, arXiv:0712.3797) \n",
    "<img src=\"figures/Eyer2007.png\" style=\"float: left; width: 90%; margin-right: 1%;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/flare.png\" style=\"float: left; width: 30%; margin-right: 1%;\"> <img src=\"figures/cepheid.png\" style=\"float: left; width: 30%; margin-right: 1%;\"> <img src=\"figures/eclipsing.png\" style=\"float: left; width: 30%; margin-right: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goals\n",
    "\n",
    "When dealing with time series data, the first thing that we want to know is if the system that we are studying is even variable (otherwise, there is no point doing time series analysis!).  In the context of frequentist statistics, this is a question of whether our data would have been obtained by chance if the no-variability null hypothesis were correct.\n",
    "\n",
    "If we find that our source *is* variable, then our time-series analysis has two main goals:\n",
    "1. Characterize the temporal correlation between different values of $y$ (i.e., characterize the \"light curve\").  For example by learning the parameters for a model.\n",
    "2. Predict future values of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the errors are known and Gaussian, we can simply compute $\\chi^2$ and the corresponding $p$ values for variation in a signal.\n",
    "\n",
    "For a sinusoidal variable signal\n",
    "    $$ y(t) = A \\sin(\\omega t)$$\n",
    "with constant errors, $\\sigma$, then\n",
    "variance is $V = \\sigma^2 + A^2/2$.\n",
    "    \n",
    "If $A=0$ (no variability, with $\\overline{y}=0$)\n",
    "- $\\chi^2_{\\rm dof}=N^{-1} \\sum_j (y_j/\\sigma)^2 \\sim V/\\sigma^2$.\n",
    "- $\\chi^2_{\\rm dof}$ has  expectation value of 1 and std dev  of $\\sqrt{2/N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If $|A|>0$ (variability)\n",
    "- $\\chi^2_{\\rm dof}$ will be larger\n",
    "than 1. \n",
    "-  probability that $\\chi^2_{\\rm dof}>1 + 3 \\sqrt{2/N}$  is about 1 in 1000 (i.e., $>3\\sigma$ above 1)\n",
    "\n",
    "If this false-positive rate is acceptable (because even without variability 1 in 1000 will be above this threshold) then the minimum detectable amplitude is $A > 2.9 \\sigma\n",
    "/ N^{1/4}$ ( from $V/\\sigma^2=1 + 3 \\sqrt{2/N}$, so that $A^2/2\\sigma^2 = 3 \\sqrt{2/N}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "N.B. Depending on how big your sample is, you may want to choose a higher threshhold.    E.g., for 1 million non-variable stars, this criterion would identify 100 as variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For $N=100$ data points (not 100 objects), the minimum detectable amplitude is $A=0.92\\sigma$\n",
    "\n",
    "For $N=1000$, $A = 0.52\\sigma$ \n",
    "\n",
    "That is, if we have enough data points, we can actually detect variability whose amplitude is smaller than the uncertainty in the measurements.\n",
    "\n",
    "Note that is the best that we can do under the assumption of the null hypothesis of no variability.  If instead we know the model (not limited to periodic variability), then we can perform a [**\"matched filter\"**](https://en.wikipedia.org/wiki/Matched_filter) analysis and improve upon this (i.e., we can positively identify lower-amplitude variability).  Indeed in a Bayesian analysis, we must have a model in mind.\n",
    "\n",
    "For non-periodic variability, the system can either be **stochastic** (like the stock market) or **temporally localized** (such as a flare/burst)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameter Estimation, Model Selection, and Classification\n",
    "\n",
    "Time series analysis can be conducted in either the time domain or the frequency domain.  We'll first start with a discussion of the time domain by revisiting tools that we have already discussed like parameter estimation and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can fit a model to $N$ data points $(t_i,y_i)$:\n",
    "\n",
    "$$y_i(t_i) = \\sum_{m=1}^M \\beta_m T_m(t_i|\\theta_m) + \\epsilon_i,$$\n",
    "\n",
    "where the functions, $T_m$, do not need to be periodic, $t_i$ does not need to be evenly sampled and $\\theta_m$ are the model parameters.\n",
    "\n",
    "So, for example, if we have\n",
    "$$y_i(t_i) = a \\sin(\\omega_0 t_i) + b \\cos (\\omega_1 t_i),$$\n",
    "then $a=\\beta_0$, $b=\\beta_1$, $\\omega_0=\\theta_0$, and $\\omega_1 = \\theta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Determining whether a variable model is favored over a non-variable model is the same as we have dealt with previously and can also be approached using the AIC, BIC, or Bayesian odds ratio.  Once the model parameters, $\\theta_m$ have been determined, we can apply supervised or unsupervised classification methods to gain further insight.\n",
    "\n",
    "Common deterministic models include\n",
    "$$T(t) = \\sin(\\omega t)$$\n",
    "and\n",
    "$$T(t) = \\exp(-\\alpha t),$$\n",
    "where the frequency, $\\omega$, and decay rate, $\\alpha$, are parameters to be estimated from the data.\n",
    "\n",
    "We will also explore a so-called \"chirp\" signal with\n",
    "$$T(t) = \\sin(\\phi + \\omega t + \\alpha t^2).$$\n",
    "\n",
    "\n",
    "(another way of thinking of a chirp is that the *frequency varies with time*; $\\omega_{\\rm instantaneous} = \\omega + \\alpha t$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fourier Analysis\n",
    "\n",
    "Fourier Analysis has the potential to be the subject for an entire class as opposed to part of a single lecture. \n",
    "\n",
    "The code below demostrates an application that you are likely familiar with: reconstruction of a complicated signal by summation of simpler trig functions:\n",
    "\n",
    "$$y_i(t_i) = Y_o + \\sum_{m=1}^M \\beta_m \\sin(m \\omega t_i + \\phi_m)   + \\epsilon_i.$$\n",
    "\n",
    "Note: **any** periodic function can be described within noise with a sufficiently large M! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset that astroML points to has moved;\n",
    "# we have to re-point astroML to the right URL\n",
    "import astroML.datasets.rrlyrae_templates\n",
    "astroML.datasets.rrlyrae_templates.DATA_URL = (\"http://www2.mpia-hd.mpg.de/~bsesar/S82_RRLyr/RRLyr_ugriz_templates.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Ivezic, Figure 10.1\n",
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#   The figure produced by this code is published in the textbook\n",
    "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
    "#   For more information, see http://astroML.github.com\n",
    "#   To report a bug or issue, use the following forum:\n",
    "#    https://groups.google.com/forum/#!forum/astroml-general\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from astroML.datasets import fetch_rrlyrae_templates\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Load the RR Lyrae template\n",
    "templates = fetch_rrlyrae_templates()\n",
    "x, y = templates['115r'].T\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "kvals = [1, 3, 8]\n",
    "subplots = [311, 312, 313]\n",
    "\n",
    "for (k, subplot) in zip(kvals, subplots):\n",
    "    ax = fig.add_subplot(subplot)\n",
    "\n",
    "    # Use FFT to fit a truncated Fourier series\n",
    "    # reconstruct using k frequencies\n",
    "    y_fft = np.fft.fft(y) # compute FFT\n",
    "    y_fft[k + 1:-k] = 0 # zero-out frequencies higher than k\n",
    "    y_fit = np.fft.ifft(y_fft).real # reconstruct using k modes\n",
    "\n",
    "    # plot the true value and the k-term reconstruction\n",
    "    ax.plot(np.concatenate([x, 1 + x]),\n",
    "            np.concatenate([y, y]), '--k', lw=2)\n",
    "    ax.plot(np.concatenate([x, 1 + x]),\n",
    "            np.concatenate([y_fit, y_fit]), color='gray')\n",
    "\n",
    "    label = \"%i mode\" % k\n",
    "    if k > 1:\n",
    "        label += 's'\n",
    "\n",
    "    ax.text(0.02, 0.1, label, ha='left', va='bottom',\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    if subplot == subplots[-1]:\n",
    "        ax.set_xlabel('phase')\n",
    "    else:\n",
    "        ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "    if subplot == subplots[1]:\n",
    "        ax.set_ylabel('amplitude')\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "    ax.set_xlim(0, 2)\n",
    "    ax.set_ylim(1.1, -0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Fourier Transform can be powerful if the signal-to-noise is high, but if not or if the signal has a complex shape or is irregularly sampled, then a probabilistic approach is better.  In astronomy, that is often the situation that we find ourselves in.  So, I'll leave the details for you to read about in $\\S$ 10.2 and we'll skip ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Temporally Localized Signals ($\\S$ 10.4)\n",
    "\n",
    "Let's look at the case of a stationary signal with an event localized in time.\n",
    "An example would be the signature of a [gravitational wave from LIGO](https://www.ligo.caltech.edu/news/ligo20160615).\n",
    "\n",
    "In this case we know the expected shape of the signal and the noise properties are understood, so we can do what is called *forward modeling*.  Specifically, we can identify the signal by using a **matched filter** (with MCMC to search for the parameter covariances).\n",
    "\n",
    "Even if we didn't know the shape of the distribution, we could use a non-parametric form to perform matched filter analysis.  Furthermore, for complex signals we can marginalize over \"nuisance\" parameters (e.g. start time or phase) that are not important for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finding a chirp or burst in a time series\n",
    "\n",
    "Imagine a stationary signal $y(t)=b_0+\\epsilon$ with an injected signal at time $T$ (possibly followed by a decay to the original level $b_0$ over some unknown time period).\n",
    "\n",
    "This injected signal could be a \"burst\"\n",
    "\n",
    "$$y(t)=b_0 + A\\exp[−\\alpha(t−T)]$$\n",
    "\n",
    "or a [\"chirp\"](https://en.wikipedia.org/wiki/Chirp)\n",
    "\n",
    "$$y(t)=b_0+A \\sin[\\omega t+\\beta t^2].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below are examples of using MCMC to fit both a burst signal and a chirp signal.  Try changing the parameters such that the system is 1) very well modeled and 2) very poorly modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Ivezic, Figure 10.25\n",
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#   The figure produced by this code is published in the textbook\n",
    "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
    "#   For more information, see http://astroML.github.com\n",
    "#   To report a bug or issue, use the following forum:\n",
    "#    https://groups.google.com/forum/#!forum/astroml-general\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Hack to fix import issue in older versions of pymc\n",
    "import scipy\n",
    "import scipy.misc\n",
    "scipy.derivative = scipy.misc.derivative\n",
    "import pymc\n",
    "\n",
    "from astroML.plotting.mcmc import plot_mcmc\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Set up toy dataset\n",
    "def burst(t, b0, A, alpha, T):\n",
    "    \"\"\"Burst model\"\"\"\n",
    "    y = np.empty(t.shape)\n",
    "    y.fill(b0) # Make y a uniform random distribution\n",
    "    mask = (t >= T) #Add the burst\n",
    "    y[mask] += A * np.exp(-alpha * (t[mask] - T))\n",
    "    return y\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Change these parameters to see what effect they have on how\n",
    "# well the system can be modeled.\n",
    "N = 100\n",
    "b0_true = 10\n",
    "A_true = 5\n",
    "alpha_true = 0.1\n",
    "T_true = 50\n",
    "sigma = 1.0\n",
    "\n",
    "t = 100 * np.random.random(N)\n",
    "\n",
    "y_true = burst(t, b0_true, A_true, alpha_true, T_true)\n",
    "y_obs = np.random.normal(y_true, sigma)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Set up MCMC sampling\n",
    "b0 = pymc.Uniform('b0', 0, 50, value=50 * np.random.random())\n",
    "A = pymc.Uniform('A', 0, 50, value=50 * np.random.random())\n",
    "T = pymc.Uniform('T', 0, 100, value=100 * np.random.random())\n",
    "log_alpha = pymc.Uniform('log_alpha', -10, 10, value=0)\n",
    "\n",
    "# uniform prior on log(alpha)\n",
    "@pymc.deterministic\n",
    "def alpha(log_alpha=log_alpha):\n",
    "    return np.exp(log_alpha)\n",
    "\n",
    "@pymc.deterministic\n",
    "def y_model(t=t, b0=b0, A=A, alpha=alpha, T=T):\n",
    "    return burst(t, b0, A, alpha, T)\n",
    "\n",
    "y = pymc.Normal('y', mu=y_model, tau=sigma ** -2, observed=True, value=y_obs)\n",
    "\n",
    "model = dict(b0=b0, A=A, T=T, log_alpha=log_alpha,\n",
    "             alpha=alpha, y_model=y_model, y=y)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Run the MCMC sampling\n",
    "def compute_MCMC_results(niter=25000, burn=4000):\n",
    "    S = pymc.MCMC(model)\n",
    "    S.sample(iter=niter, burn=burn)\n",
    "    traces = [S.trace(s)[:] for s in ['b0', 'A', 'T', 'alpha']]\n",
    "\n",
    "    M = pymc.MAP(model)\n",
    "    M.fit()\n",
    "    fit_vals = (M.b0.value, M.A.value, M.alpha.value, M.T.value)\n",
    "\n",
    "    return traces, fit_vals\n",
    "\n",
    "traces, fit_vals = compute_MCMC_results()\n",
    "\n",
    "labels = ['$b_0$', '$A$', '$T$', r'$\\alpha$']\n",
    "limits = [(9.2, 11.2), (2, 12), (45, 55), (0.0, 0.25)]\n",
    "true = [b0_true, A_true, T_true, alpha_true]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.subplots_adjust(bottom=0.1, top=0.95,\n",
    "                    left=0.1, right=0.95,\n",
    "                    hspace=0.05, wspace=0.05)\n",
    "\n",
    "# This function plots multiple panels with the traces\n",
    "plot_mcmc(traces, labels=labels, limits=limits, true_values=true, fig=fig,\n",
    "          bins=30, colors='k')\n",
    "\n",
    "# Plot the model fit\n",
    "ax = fig.add_axes([0.5, 0.7, 0.45, 0.25])\n",
    "t_fit = np.linspace(0, 100, 101)\n",
    "y_fit = burst(t_fit, *fit_vals)\n",
    "\n",
    "ax.scatter(t, y_obs, s=9, lw=0, c='k')\n",
    "ax.plot(t_fit, y_fit, '-k')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel(r'$h_{\\rm obs}$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Ivezic, Figure 10.26\n",
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#   The figure produced by this code is published in the textbook\n",
    "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
    "#   For more information, see http://astroML.github.com\n",
    "#   To report a bug or issue, use the following forum:\n",
    "#    https://groups.google.com/forum/#!forum/astroml-general\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Hack to fix import issue in older versions of pymc\n",
    "import scipy\n",
    "import scipy.misc\n",
    "scipy.derivative = scipy.misc.derivative\n",
    "import pymc\n",
    "\n",
    "from astroML.plotting.mcmc import plot_mcmc\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Set up toy dataset\n",
    "def chirp(t, b0, beta, A, omega):\n",
    "    return b0 + A * np.sin(omega * t + beta * t * t)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Change these parameters to see what effect they have on how\n",
    "# well the system can be modeled.\n",
    "N = 100\n",
    "b0_true = 10\n",
    "A_true = 5\n",
    "beta_true = 0.01\n",
    "omega_true = 0.1\n",
    "sigma = 2.0\n",
    "\n",
    "t = 100 * np.random.random(N)\n",
    "\n",
    "y_true = chirp(t, b0_true, beta_true, A_true, omega_true)\n",
    "y_obs = np.random.normal(y_true, sigma)\n",
    "\n",
    "t_fit = np.linspace(0, 100, 1000)\n",
    "y_fit = chirp(t_fit, b0_true, beta_true, A_true, omega_true)\n",
    "\n",
    "i = np.argsort(t)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Set up MCMC sampling\n",
    "b0 = pymc.Uniform('b0', 0, 50, value=50 * np.random.random())\n",
    "A = pymc.Uniform('A', 0, 50, value=50 * np.random.random())\n",
    "log_beta = pymc.Uniform('log_beta', -10, 10, value=-4.6)\n",
    "log_omega = pymc.Uniform('log_omega', -10, 10, value=-2.3)\n",
    "\n",
    "# uniform prior on log(beta)\n",
    "@pymc.deterministic\n",
    "def beta(log_beta=log_beta):\n",
    "    return np.exp(log_beta)\n",
    "\n",
    "# uniform prior on log(omega)\n",
    "@pymc.deterministic\n",
    "def omega(log_omega=log_omega):\n",
    "    return np.exp(log_omega)\n",
    "\n",
    "@pymc.deterministic\n",
    "def y_model(t=t, b0=b0, A=A, beta=beta, omega=omega):\n",
    "    return chirp(t, b0, beta, A, omega)\n",
    "\n",
    "y = pymc.Normal('y', mu=y_model, tau=sigma ** -2, observed=True, value=y_obs)\n",
    "\n",
    "model = dict(b0=b0, A=A,\n",
    "             log_beta=log_beta, beta=beta,\n",
    "             log_omega=log_omega, omega=omega,\n",
    "             y_model=y_model, y=y)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Run the MCMC sampling (saving results to a pickle)\n",
    "def compute_MCMC_results(niter=20000, burn=2000):\n",
    "    S = pymc.MCMC(model)\n",
    "    S.sample(iter=niter, burn=burn)\n",
    "    traces = [S.trace(s)[:] for s in ['b0', 'A', 'omega', 'beta']]\n",
    "\n",
    "    M = pymc.MAP(model)\n",
    "    M.fit()\n",
    "    fit_vals = (M.b0.value, M.beta.value, M.A.value, M.omega.value)\n",
    "\n",
    "    return traces, fit_vals\n",
    "\n",
    "traces, fit_vals = compute_MCMC_results()\n",
    "\n",
    "labels = ['$b_0$', '$A$', r'$\\omega$', r'$\\beta$']\n",
    "limits = [(9.5, 11.3), (3.6, 6.4), (0.065, 0.115), (0.00975, 0.01045)]\n",
    "true = [b0_true, A_true, omega_true, beta_true]\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Find the Maximum a posteriori values\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.axes([0.5, 0.7, 0.45, 0.25])\n",
    "t_fit = np.linspace(0, 100, 1001)\n",
    "y_fit = chirp(t_fit, *fit_vals)\n",
    "plt.scatter(t, y_obs, s=9, lw=0, c='k')\n",
    "plt.plot(t_fit, y_fit, '-k')\n",
    "plt.xlim(0, 100)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel(r'$h_{\\rm obs}$')\n",
    "\n",
    "# This function plots multiple panels with the traces\n",
    "plot_mcmc(traces, labels=labels, limits=limits, true_values=true, fig=fig,\n",
    "          bins=30, bounds=[0.12, 0.08, 0.95, 0.91], colors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the case of the chirp example, if you make `omega_true = 0.5`, you get a poor result even with `N=1000`.  Keeping $N$ the same, how could you improve your result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Periodic signals ($\\S$ 10.3)\n",
    "\n",
    "Many systems have **periodic** signals.  This is especially true in astronomy (e.g., RR-Lyrae, Cepheids, eclipsing binaries).\n",
    "\n",
    "What we want to be able to do is to detect variability and measure the period in the face of both noisy and incomplete data.\n",
    "\n",
    "For example, the figure on the left is the kind of data that you *want* to have, whereas the figure on the right is the kind of data that you are more likely to have.\n",
    "<img src=\"figures/rrlyrae-good.png\" style=\"float: left; width: 40%; margin-right: 1%;\"> <img src=\"figures/rrlyrae-bad.png\" style=\"float: left; width: 40%; margin-right: 1%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a periodic signal we have:\n",
    "\n",
    "$$y(t+P)=y(t),$$ where $P$ is the period.\n",
    "\n",
    "We can create a *phased light curve* that plots the data as function of phase:\n",
    "$$\\phi=\\frac{t}{P} − {\\rm int}\\left(\\frac{t}{P}\\right),$$\n",
    "\n",
    "where ${\\rm int}(x)$ returns the integer part of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example in the case below, when the pattern starts to repeat, we reset the $t$ axis to 0:\n",
    "![Eclipsing Binary](http://www.nasa.gov/centers/ames/images/content/588733main_binary-stars-lightcurve.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Single Sinusoid\n",
    "\n",
    "Let's take the case where the data are drawn from a single sinusoidal signal:\n",
    "\n",
    "$$y(t)=A \\sin(\\omega t+\\phi)+\\epsilon$$\n",
    "\n",
    "and determine whether or not the data are indeed consistent with periodic variability and, if so, what is the period.\n",
    "\n",
    "We can rewrite the argument as $\\omega(t−t_0)$ (removing the phase term) and use trig identies to rewrite the model as\n",
    "\n",
    "$$y(t)=a \\sin(\\omega t)+b \\cos(\\omega t),$$\n",
    "\n",
    "where $A=(a^2+b^2)^{1/2}$ and $\\phi=\\tan^{−1}(b/a)$.\n",
    "\n",
    "The model is now linear with respect to coefficients $a$ and $b$ (and nonlinear only with respect to frequency, $\\omega$).  We now seek to determine the values of those parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assuming constant uncertainties on the data, the likelihood for this model becomes,\n",
    "\n",
    "$$L\\equiv p({t,y}|\\omega,a,b,\\sigma)=\\prod^N_{j=1}\\frac{1}{\\sqrt{2π}\\sigma} \\exp \\left(\\frac{−[y_j−a \\sin(\\omega t_j)−b \\cos(\\omega t_j)]}{2\\sigma^2} \\right), $$\n",
    "\n",
    "where $y_i$ is the measurement (e.g., the brightness of a star) taken at time $t_i$.\n",
    "\n",
    "Assuming uniform priors on $a, b, \\omega$, and $\\sigma$ (which gives nonuniform priors on $A$ and $\\phi$) the posterior can be simplified to\n",
    "\n",
    "$$p(\\omega,a,b,\\sigma|{t,y}) \\propto \\sigma^{−N} \\exp \\left(\\frac{−NQ}{2\\sigma^2} \\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "with\n",
    "\n",
    ">$Q= V - {2\\over N} \\left[ a \\, I(\\omega) + b \\, R(\\omega) - a\\, b\\, M(\\omega) - {1 \\over 2} a^2 \\, S(\\omega) - {1 \\over 2} b^2 \\,C(\\omega)\\right]$\n",
    "\n",
    "and\n",
    "\n",
    ">$            V = {1\\over N} \\sum_{j=1}^N y_j^2$\n",
    "\n",
    ">$       I(\\omega) = \\sum_{j=1}^N y_j   \\sin(\\omega t_j)$\n",
    "\n",
    ">$ R(\\omega) = \\sum_{j=1}^N y_j  \\cos(\\omega t_j)$\n",
    "\n",
    ">$      M(\\omega) = \\sum_{j=1}^N \\sin(\\omega t_j) \\, \\cos(\\omega t_j)$\n",
    "\n",
    ">$      S(\\omega) = \\sum_{j=1}^N \\sin^2(\\omega t_j)$\n",
    "\n",
    ">$C(\\omega) = \\sum_{j=1}^N  \\cos^2(\\omega t_j)$\n",
    "\n",
    "*NOTE* I, R, M, S, C only depend on $\\omega$ and the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### The posterior for many, randomly spaced, observations\n",
    "\n",
    "If N>>1 and we have data that extends longer than the period\n",
    "\n",
    "$S(\\omega) \\approx C(\\omega) \\approx N/2$ and $M(\\omega) \\ll N/2$ and\n",
    "\n",
    ">$Q \\approx V - {2\\over N} \\left[ a \\, I(\\omega) + b \\, R(\\omega)\\right]  + {1 \\over 2} (a^2 + b^2)$\n",
    "\n",
    "If we marginalize over $a$ and $b$ (as we are interested in the period)\n",
    "\n",
    ">$  p(\\omega,\\sigma|\\{t,y\\}) \\propto  \\sigma^{-(N-2)} \\exp \\left( { - N V \\over 2 \\sigma^2} + { P(\\omega) \\over \\sigma^2}       \\right)$\n",
    "\n",
    "with $P(\\omega) = {1 \\over N} [ I^2(\\omega) + R^2(\\omega)]$\n",
    "\n",
    "if we know the noise $\\sigma$ then \n",
    "\n",
    ">$   p(\\omega|\\{t,y\\}, \\sigma) \\propto \\exp \\left( { P(\\omega) \\over \\sigma^2} \\right)$\n",
    "\n",
    "and we now have the posterior for $\\omega$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can follow the details of the math in $\\S$ 10.3.1, but in short, if we marginalize over $a$ and $b$ (since we really just care about $\\omega$) and if we know the noise level, $\\sigma$, then the posterior further simplifies to\n",
    "\n",
    "$$ p(\\omega|\\{t,y\\}, \\sigma) \\propto \\exp \\left(\\frac{P(\\omega)}{\\sigma^2} \\right),$$\n",
    "\n",
    "where $P(\\omega)$ is the [periodogram](https://en.wikipedia.org/wiki/Periodogram), which is just a plot of the \"power\" at each possible period (as illustrated below):\n",
    "\n",
    "<img src=\"figures/periodogram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Significance of the peaks in the periodogram\n",
    "\n",
    "The amplitude(s) of the periodic signal can be derived from the posterior in much the same way as we do for MLE, by taking the derivative of the posterior with respect to $a$ and $b$.\n",
    "\n",
    "But what we really want to know is the \"best value\" $\\omega$? \n",
    "\n",
    "The $\\chi^2$ is given by\n",
    "$$\\chi^2(\\omega) \\equiv {1 \\over \\sigma^2} \\sum_{j=1}^N [y_j-y(t_j)]^2 =\n",
    "  {1 \\over \\sigma^2} \\sum_{j=1}^N [y_j- a_0\\, \\sin(\\omega t_j) - b_0 \\, \\cos(\\omega t_j)]^2,$$\n",
    "  \n",
    "which we can simplify to\n",
    "\n",
    "$$\\chi^2(\\omega) =  \\chi_0^2 \\, \\left[1 - {2 \\over N \\, V}  \\, P(\\omega) \\right],$$\n",
    "\n",
    "where, again, $P(\\omega)$ is the periodogram and $\\chi_0^2$ is the $\\chi^2$ for a model with $y(t)$=constant:\n",
    "\n",
    "$$  \\chi_0^2 = {1 \\over \\sigma^2} \\sum_{j=1}^N y_j^2 = {N \\, V \\over \\sigma^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll now renormalise the periodogram, defining the [Lomb-Scargle periodogram](https://en.wikipedia.org/wiki/Least-squares_spectral_analysis#The_Lomb.E2.80.93Scargle_periodogram) as\n",
    "\n",
    "$$P_{\\rm LS}(\\omega) = \\frac{2}{N V} P(\\omega),$$  where $0 \\le P_{\\rm LS}(\\omega) \\le 1$.\n",
    "\n",
    "With this renormalization, the reduction in $\\chi^2(\\omega)$ for the harmonic model, \n",
    "relative to $\\chi^2$ for the pure noise model, $\\chi^2_0$ is\n",
    "$${\\chi^2(\\omega) \\over \\chi^2_0}=  1 - P_{LS}(\\omega).$$\n",
    "\n",
    "To determine if our source is variable or not, we first compute $P_{\\rm LS}(\\omega)$ and then model the odds ratio for our variability model vs. a no-variability model.\n",
    "\n",
    "If our variability model is \"correct\", then the peak of $P(\\omega)$ [found by grid search] gives the best $\\omega$ and the $\\chi^2$ at $\\omega = \\omega_0$ is $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the true frequency is $\\omega_0$ then the maximum peak in the periodogram should have a height\n",
    "\n",
    "$$P(\\omega_0) = {N \\over 4} (a_0^2 + b_0^2)$$\n",
    "\n",
    "and standard deviation\n",
    "$$      \\sigma_P(\\omega_0)  = {\\sqrt{2} \\over 2} \\, \\sigma^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Properties of LS and the periodogram\n",
    "- The expected heights of the peaks in a periodogram don't depend on $\\sigma$ but their variation in height do.\n",
    "- For $P_{\\rm LS}(\\omega_0)$, with no noise the peak approaches 1. As noise increases, $P_{\\rm LS}(\\omega_0)$ decreases and is ``buried'' in the background  noise.\n",
    "- To estimate the uncertainty on the peaks we can use a bootstrap approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below is an example of a LS periodogram generated using 100 points drawn from $y(t|P) = 10 + \\sin(2\\pi t/P),$ with $P=0.3$.  \n",
    "\n",
    "[http://www.astroml.org/gatspy/periodic/lomb_scargle.html](http://www.astroml.org/gatspy/periodic/lomb_scargle.html) gives more information on astroML's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Similar to Figure 10.15\n",
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "from matplotlib import pyplot as plt\n",
    "from astroML.time_series import\\\n",
    "    lomb_scargle, lomb_scargle_BIC, lomb_scargle_bootstrap\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Generate Data\n",
    "np.random.seed(0)\n",
    "N = 100\n",
    "P = 0.3\n",
    "\n",
    "t = np.random.randint(100, size=N) + 0.3 + 0.4 * np.random.random(N)\n",
    "y = 10 + np.sin(2 * np.pi * t / P)\n",
    "dy = 0.5 + 0.5 * np.random.random(N)\n",
    "y_obs = np.random.normal(y, dy)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Compute periodogram\n",
    "period = 10 ** np.linspace(-1, 0, 10000)\n",
    "omega = 2 * np.pi / period\n",
    "PS = lomb_scargle(t, y_obs, dy, omega, generalized=True)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Get significance via bootstrap\n",
    "D = lomb_scargle_bootstrap(t, y_obs, dy, omega, generalized=True,\n",
    "                           N_bootstraps=500, random_state=0)\n",
    "sig1, sig5 = np.percentile(D, [99, 95])\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.subplots_adjust(left=0.1, right=0.9, hspace=0.25)\n",
    "\n",
    "# First panel: the data\n",
    "ax = fig.add_subplot(211)\n",
    "ax.errorbar(t, y_obs, dy, fmt='.k', lw=1, ecolor='gray')\n",
    "ax.set_xlabel('time (days)')\n",
    "ax.set_ylabel('flux')\n",
    "ax.set_xlim(-5, 105)\n",
    "\n",
    "# Second panel: the periodogram & significance levels\n",
    "ax1 = fig.add_subplot(212, xscale='log')\n",
    "ax1.plot(period, PS, '-', c='black', lw=1, zorder=1)\n",
    "ax1.plot([period[0], period[-1]], [sig1, sig1], ':', c='black')\n",
    "ax1.plot([period[0], period[-1]], [sig5, sig5], ':', c='black')\n",
    "\n",
    "ax1.annotate(\"\", (0.3, 0.65), (0.3, 0.85), ha='center',\n",
    "             arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "ax1.set_xlim(period[0], period[-1])\n",
    "ax1.set_ylim(-0.05, 0.85)\n",
    "\n",
    "ax1.set_xlabel(r'period (days)')\n",
    "ax1.set_ylabel('power')\n",
    "\n",
    "# Twin axis: label BIC on the right side\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylim(tuple(lomb_scargle_BIC(ax1.get_ylim(), y_obs, dy)))\n",
    "ax2.set_ylabel(r'$\\Delta BIC$')\n",
    "\n",
    "ax1.xaxis.set_major_formatter(plt.FormatStrFormatter('%.1f'))\n",
    "ax1.xaxis.set_minor_formatter(plt.FormatStrFormatter('%.1f'))\n",
    "ax1.xaxis.set_major_locator(plt.LogLocator(10))\n",
    "ax1.xaxis.set_major_formatter(plt.FormatStrFormatter('%.3g'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If that isn't impressive, try changing the period to 5-10 days and the number of points to 200-300 (you'll need to increase `period` array as appropriate, note that it is a log quantity) to compare this to a situation that is more obvious.  Now are you impressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### False Alarm Probability\n",
    "\n",
    "Is there a chance that these peaks are due to random fluctuations and that \n",
    "underlying time series is simply noise? \n",
    "\n",
    "It is hard to answer this question with simple analytic expressions (this is a \n",
    "complex case involving multiple hypothesis testing and a window function).\n",
    "For details see \"Understanding the Lomb-Scargle Periodogram\" by Jake VanderPlas\n",
    "(2017, [arXiv:1703.09824](https://arxiv.org/abs/1703.09824)). \n",
    "\n",
    "Fortunately, we can compute false alarm probability using numerical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "FAP is **not** the probability that we really found the correct period of a variable object.\n",
    "\n",
    "Rather, it is probability that we would get the strongest periodogram peak that high\n",
    "from a time series that was pure noise. \n",
    "\n",
    "To get the model probability ratio of variable star vs. noise (constant flux), we need to take into\n",
    "account their prior probabilities (Bayes!): \n",
    "\n",
    "$$ {p(Var\\,|\\,Peak) \\over p(Const\\,|\\,Peak)} = {p(Peak\\,|\\, Var) \\over p(Peak\\,|\\,Const)} \\, {p(Var) \\over p(Const)}.\n",
    "$$\n",
    "\n",
    "Here FAP corresponds to $p(Peak\\,|\\,Const)$, and with $p(Peak\\,|\\, Var) \\sim 1$, we have\n",
    "\n",
    "$$ {p(Var\\,|\\,Peak) \\over p(Const\\,|\\,Peak)} = {1 \\over FAP} \\, {p(Var) \\over p(Const)}. $$\n",
    "\n",
    "The ratio of priors [p(Var)/p(Const)] is the fraction of variable stars in the studied population. \n",
    "It is typically a few percent (of the order 0.01) - therefore, in order to have a reliable detection of\n",
    "period (say, LHS $>$10), FAP should be at least as small as 0.001. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The two horizontal dashed lines in the periodogram above correspond to FAPs of\n",
    "0.01 and 0.001. \n",
    "\n",
    "These FAPs were computed using a bootstrap method. Lomb-Scargle implementation \n",
    "in astropy includes several other methods (much faster but less accurate),\n",
    "as shown next.\n",
    "\n",
    "**NOTE:** the FAP in a given periodogram is a function of time sampling and\n",
    "measurement errors - it needs to be (re)computed every time you produce a\n",
    "new periodogram! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.stats import LombScargle\n",
    "    \n",
    "def showFAP4LS(t, y, dy):\n",
    "\n",
    "    ls = LombScargle(t, y, dy, normalization='standard')\n",
    "    zmax = 0.23\n",
    "    z = np.linspace(0.001, zmax, 10000)\n",
    "    \n",
    "    def false_alarm(method):\n",
    "        return ls.false_alarm_probability(z, method=method, maximum_frequency=5)\n",
    "\n",
    "    fa_boot = ls.false_alarm_probability(z, method='bootstrap',\n",
    "                                         maximum_frequency=5,\n",
    "                                         method_kwds=dict(random_seed=42))\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "    ax.plot(z, false_alarm('naive'), label='naive estimate')\n",
    "    ax.plot(z, false_alarm('baluev'), label='Baluev estimate')\n",
    "    ax.plot(z, false_alarm('davies'), ':k', label='Davies bound')\n",
    "    ax.plot(z, fa_boot, '-k', label='bootstrap estimate')\n",
    "\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.set(yscale='log',\n",
    "           title='False Alarm Estimates (N=100)',\n",
    "           xlim=(0, zmax), ylim=(0.001, 1.5),\n",
    "           xlabel='Value of Highest Periodogram Peak',\n",
    "           ylabel='False Alarm Probability');\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "showFAP4LS(t, y_obs, dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aliasing\n",
    "\n",
    "But why did we have 3 peaks above the line FAP=0.001??? \n",
    "\n",
    "The two most common problems are sampling aliases (e.g. observations spaced \n",
    "by roughly 1 day) and inability of a single sinusoid to fit the shape of light\n",
    "curve (always check if there is another significant peak at twice the best-fit \n",
    "period). \n",
    "\n",
    "For details see Section 7.2 in \"Understanding the Lomb-Scargle Periodogram\" \n",
    "by Jake VanderPlas (2017, [arXiv:1703.09824](https://arxiv.org/abs/1703.09824)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Add 10.16 and 10.17?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generalized Lomb-Scargle\n",
    "\n",
    "The Lomb-Scargle periodogram is a fit to a model:\n",
    "\n",
    "$$y(t)=a \\sin(\\omega t)+b \\cos(\\omega t),$$\n",
    "\n",
    "whose mean is zero. In reality, the observed variability is typically around some (mean) value, not zero. We deal with this by subtracting the mean of the sample $\\overline{y}$ from the data before performing the periodogram analysis.\n",
    "\n",
    "That only works if $\\overline{y}$ is a good estimator of the mean of the distribution, $y(t)$ -- if the data is equally sampled at all phases. However, in practice, the data may not equally sample all of the phases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, consider the case of a star that has a period of one day and the fact that a single optical telescope only takes data at night. In that case you we might get something like the top panel below:\n",
    "\n",
    "![Ivezic, Figure 10.16](http://www.astroml.org/_images/fig_LS_sg_comparison_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The \"generalized\" Lomb-Scargle approach (also implemented in astroML) can help with this as can be seen in the bottom panel above. It fits the model with non-zero mean:\n",
    "\n",
    "$$y(t)=a \\sin(\\omega t)+b \\cos(\\omega t) + C$$\n",
    "\n",
    "See also [Figure 10.16](http://www.astroml.org/book_figures/chapter10/fig_LS_sg_comparison.html) in the textbook (and note the erratum!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiband LS periodograms\n",
    "\n",
    "One of the issues that we are going to be dealing with in astronomy over the next decade as the LSST project comes online is the problem of sparsely-sampled light curves, but with multiple light curves for each object -- one for each \"bandpass\" as seen below:\n",
    "\n",
    "<img src=\"figures/multibandLS.png\" style=\"float: right; width: 100%; margin-right: 1%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The generalized LS was an extension to account for the mean value. We can build on this to account for multiple bands by fitting for a global period and a per-band period\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "  &y_k(t|\\omega,\\theta) =\n",
    "  \\theta_0 + \\sum_{n=1}^{N_{base}} \\left[\\theta_{2n - 1}\\sin(n\\omega t) + \\theta_{2n}\\cos(n\\omega t)\\right] +&\\nonumber\n",
    "  &\\theta^{(k)}_0 + \\sum_{n=1}^{N_{band}} \\left[\\theta^{(k)}_{2n - 1}\\sin(n\\omega t) + \\theta^{(k)}_{2n}\\cos(n\\omega t)\\right].&\n",
    "\\end{eqnarray}$\n",
    "\n",
    "(Actually this illustrates a global offset and per-band offsets and not periods.)\n",
    "\n",
    "The total number of parameters for $K$ filters is then $M_K = (2N_{base} + 1) + K(2N_{band} + 1)$. \n",
    "\n",
    "To keep the parameters constrained we apply regularization (see regression).\n",
    "\n",
    "The important feature of this model is that _all bands_ share the same base parameters, $\\theta$, while their offsets $\\theta^{(k)}$ are determined individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below we show the multi-band light curves of an RR Lyrae star as an example.  \n",
    "\n",
    "A fit with just one base term isn't so great:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from gatspy.datasets import fetch_rrlyrae\n",
    "rrlyrae = fetch_rrlyrae()\n",
    "lcid = rrlyrae.ids[0]\n",
    "\n",
    "t, y, dy, filts = rrlyrae.get_lightcurve(lcid)\n",
    "period = rrlyrae.get_metadata(lcid)['P']\n",
    "\n",
    "from gatspy.periodic import LombScargleMultiband\n",
    "model = LombScargleMultiband(Nterms_base=1, Nterms_band=0)\n",
    "model.fit(t, y, dy, filts)\n",
    "periods = np.linspace(period - 0.1, period + 0.1, 2000)\n",
    "power = model.periodogram(periods)\n",
    "\n",
    "def plot_model(model, lcid):\n",
    "    t, y, dy, filts = rrlyrae.get_lightcurve(lcid)\n",
    "    model.fit(t, y, dy, filts)\n",
    "    \n",
    "    tfit = np.linspace(0, period, 1000)\n",
    "    for filt in 'ugriz':\n",
    "        mask = (filts == filt)\n",
    "        eb = plt.errorbar(t[mask] % period, y[mask], dy[mask], fmt='.', label=filt)\n",
    "        yfit = model.predict(tfit, filt, period=period)\n",
    "        plt.plot(tfit, yfit, color=eb[0].get_color())\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend(ncol=3, loc='upper left')\n",
    "    \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plot_model(LombScargleMultiband(Nterms_base=1, Nterms_band=0), lcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But with 4 base terms, we get excellent results.  Note that this works well for this case where we don't expect $\\omega$ to be bandpass dependent, but it might not work so well for quasars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plot_model(LombScargleMultiband(Nterms_base=4, Nterms_band=1), lcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "With parameters of a periodic model in hand, we can attempt to classify our sources.  Either using supervised methods if we have labeled examples or unsupervised methods if we do not.\n",
    "\n",
    "The examples below show that a sample of variable stars can be divided into different groups.  The first plot shows an unsupervised clustering analysis and the second is a supervised GMMB classification.\n",
    "\n",
    "![Ivezic, Figure 10.20](http://www.astroml.org/_images/fig_LINEAR_clustering_1.png)\n",
    "\n",
    "![Ivezic, Figure 10.22](http://www.astroml.org/_images/fig_LINEAR_GMMBayes_1.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
