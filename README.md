# PHYS_T480_F18

This is the repository for PHYS T480/580 "Big Data Physics: Methods of Machine Learning" at Drexel University, taught by Prof. Gordon Richards.  The course syllabus can be found at http://www.physics.drexel.edu/~gtr/teaching/physT480/

The course is a series of jupyter notebooks, where I have drawn heavily from resources from the following people/places:

Jake Vanderplas (University of Washington) -- one of the primary code developers of scikit-learn and astroML.  I draw a lot from https://github.com/jakevdp/ESAC-stats-2014, but you can find a lot more from him too: https://github.com/jakevdp/.

Zeljko Ivezic (University of Washington) -- the lead author of the textbook that we use (http://press.princeton.edu/titles/10159.html) and instructor (along with Mario Juric) for https://github.com/uw-astr-302-w18/astr-302-w18

Andy Connolly (University of Washington), particularly http://cadence.lsst.org/introAstroML/

Karen Leighly (University of Oklahoma), particularly http://http://seminar.ouml.org/

Adam Miller (Northwestern University), particularly https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/

Jo Bovy (University of Toronto), particularly http://astro.utoronto.ca/~bovy/teaching.html

Thomas Wiecki, particularly http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/

My thanks also to Maher Harb (Drexel University), Liam Coatman (Cambridge), Nathalie Thibert (UWO), and Kevin Footer (Deloitte).

I have tried to be careful about properly attributing anything drawn from these resources, but if it isn't clear where something comes from, it is probably there.
Others are welcome to draw from here for their own Machine Learning courses.  Please send any corrections to gtr@physics.drexel.edu.

If you have any interest in using these materials for your own Machine Learning course, please e-mail me and I'll send you my post lecture notes about what worked, what didn't, what took too long, what didn't take long enough -- basically what I would change for next time.

## Schedule

Lecture 1 (9/24): Motivation.ipynb and InitialSetup.ipynb

Lecture 2 (9/26): HistogramExample.ipynb

Lecture 3 (10/1): BasicStats.ipynb

Lecture 4 (10/3): BasicStats2.ipynb

Lecture 5 (10/10): Inference.ipynb

Lecture 6 (10/15): Inference2.ipynb

Lecture 7 (10/17): Scikit-Learn-Intro.ipynb

Lecture 8 (10/22): KernelDensityEstimation.ipynb and NearestNeighbor.ipynb

Lecture 9 (10/24): MixtureModel.ipynb and Clustering.ipynb

Lecture 10 (10/29): DimensionReduction.ipynb

Lecture 11 (10/31): NonlinearDimensionReduction.ipynb

Lecture 12 (11/5): Regression.ipynb

Lecture 13 (11/7): Regression2.ipynb

Lecture 14 (11/12): Classification.ipynb

Lecture 15 (11/14): No Lecture

Lecture 16 (11/19): Classification2.ipynb

Lecture 17 (11/26): TimeSeries.ipynb

Lecture 18 (11/28): TimeSeries2.ipynb and NeuralNetworks.ipynb

Lecture 19 (12/3): Project Presentations

Lecture 20 (12/5): Project Presentations
